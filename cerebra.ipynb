{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "A3OtJsW4Vf1L",
        "7mva7e_UVpvl",
        "gQq-PIOJWU5q",
        "A7idTEleWzSW"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPXoSETi3YC3IoAaxi3OyLG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shaheer-op9872uw/Beyond-Transformers/blob/main/cerebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse Attention Simulation"
      ],
      "metadata": {
        "id": "A3OtJsW4Vf1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Sparse Attention Simulation**\n",
        "*This simulates a simple sparse attention mechanism on random input data, so you can see if it behaves as expected — focusing only on a subset of tokens instead of everything (like full attention).*"
      ],
      "metadata": {
        "id": "bcWmA5JaSNgz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g31xCb2SJ8I",
        "outputId": "181a1cf0-41c7-4088-f884-b180b97c4495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparse Attention Output shape: (10, 16)\n",
            "[[0.2334306  0.63932609 0.46888396 0.78867215 0.37987704 0.8597693\n",
            "  0.37915969 0.12817798 0.57928303 0.34558759 0.35538377 0.8364209\n",
            "  0.79639351 0.53876081 0.58670459 0.56919519]\n",
            " [0.31233891 0.47466897 0.4529609  0.76526589 0.42674519 0.83663004\n",
            "  0.36523346 0.20788432 0.37150793 0.5019981  0.37915337 0.77046802\n",
            "  0.69263274 0.50652655 0.54766205 0.64610714]\n",
            " [0.37838446 0.69867238 0.53772843 0.58741839 0.49003107 0.74128859\n",
            "  0.24922425 0.25992805 0.53971351 0.36476227 0.44547351 0.66065829\n",
            "  0.62615108 0.47503335 0.47049162 0.65031103]\n",
            " [0.34032499 0.44417891 0.41493526 0.75975132 0.38689723 0.83632227\n",
            "  0.40193518 0.19024129 0.3525045  0.54464527 0.3773553  0.73187841\n",
            "  0.71090308 0.55472871 0.59598056 0.65326334]\n",
            " [0.30529064 0.53264709 0.446321   0.75599677 0.39287443 0.78283224\n",
            "  0.43690817 0.30750985 0.50647103 0.37676002 0.3933274  0.82676492\n",
            "  0.75991291 0.38206365 0.56275784 0.66393642]\n",
            " [0.28667606 0.52090305 0.46662762 0.77214758 0.42630664 0.84208472\n",
            "  0.35884619 0.19399808 0.4247447  0.45449219 0.37410435 0.79590181\n",
            "  0.71194106 0.50137634 0.54406252 0.62636862]\n",
            " [0.31766739 0.49817886 0.45435734 0.75127356 0.41840935 0.77593598\n",
            "  0.42190045 0.33637313 0.45732863 0.40416322 0.40061045 0.822018\n",
            "  0.72625542 0.3558925  0.53636258 0.68290453]\n",
            " [0.3398526  0.44555544 0.41457721 0.75993047 0.38582593 0.83657139\n",
            "  0.40260162 0.18912124 0.35451412 0.5435293  0.37706978 0.73206044\n",
            "  0.71229537 0.5557567  0.59708476 0.65252115]\n",
            " [0.30400593 0.54074175 0.44103809 0.75664352 0.38217144 0.78354702\n",
            "  0.44531564 0.30042549 0.52101682 0.37012311 0.39152004 0.82618737\n",
            "  0.77180537 0.39030291 0.57396645 0.6597609 ]\n",
            " [0.45542828 0.60613188 0.38998784 0.30464987 0.33836757 0.65753189\n",
            "  0.21480163 0.27328645 0.66850571 0.30359082 0.58187778 0.38642665\n",
            "  0.48946202 0.62735692 0.57482639 0.73473574]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sparse_attention(query, key, value, top_k):\n",
        "    \"\"\"\n",
        "    Simple sparse attention:\n",
        "    - For each query vector, attend only to top_k keys based on dot-product similarity.\n",
        "    - query, key, value shapes: (seq_len, dim)\n",
        "    \"\"\"\n",
        "    seq_len, dim = query.shape\n",
        "\n",
        "    # Compute similarity scores: (seq_len, seq_len)\n",
        "    scores = np.dot(query, key.T)\n",
        "\n",
        "    # For each query, find indices of top_k keys\n",
        "    top_indices = np.argsort(scores, axis=1)[:, -top_k:]\n",
        "\n",
        "    # Initialize output\n",
        "    output = np.zeros_like(query)\n",
        "\n",
        "    # Compute attention for each query position\n",
        "    for i in range(seq_len):\n",
        "        # Select top_k scores and keys for query i\n",
        "        selected_scores = scores[i, top_indices[i]]\n",
        "        selected_values = value[top_indices[i]]\n",
        "\n",
        "        # Softmax over top_k scores\n",
        "        exp_scores = np.exp(selected_scores - np.max(selected_scores))\n",
        "        weights = exp_scores / np.sum(exp_scores)\n",
        "\n",
        "        # Weighted sum of selected values\n",
        "        output[i] = np.sum(weights[:, None] * selected_values, axis=0)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Test parameters\n",
        "seq_len = 10    # number of tokens\n",
        "dim = 16        # embedding dimension\n",
        "top_k = 3       # sparsity: attend only to top 3 keys per query\n",
        "\n",
        "# Random input embeddings for query, key, value\n",
        "np.random.seed(42)\n",
        "query = np.random.rand(seq_len, dim)\n",
        "key = np.random.rand(seq_len, dim)\n",
        "value = np.random.rand(seq_len, dim)\n",
        "\n",
        "# Run sparse attention\n",
        "output = sparse_attention(query, key, value, top_k)\n",
        "\n",
        "print(\"Sparse Attention Output shape:\", output.shape)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Memory & Compute Savings:**\n",
        "*By focusing only on top-k keys, the amount of computation and memory used drops significantly compared to full attention. This simulates the core idea behind sparse attention in models like Cerebra.*"
      ],
      "metadata": {
        "id": "vRNg18kzSxZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "seq_len = 1000    # sequence length (large for memory test)\n",
        "feature_dim = 64  # feature dimension\n",
        "top_k = 20        # sparse top-k\n",
        "\n",
        "# Generate random query, key, value matrices\n",
        "queries = np.random.rand(seq_len, feature_dim)\n",
        "keys = np.random.rand(seq_len, feature_dim)\n",
        "values = np.random.rand(seq_len, feature_dim)\n",
        "\n",
        "# Normal full attention complexity (n^2)\n",
        "full_attention_cost = seq_len * seq_len * feature_dim\n",
        "\n",
        "# Sparse top-k attention complexity (n * k)\n",
        "sparse_attention_cost = seq_len * top_k * feature_dim\n",
        "\n",
        "print(f\"Full attention compute cost (approx): {full_attention_cost}\")\n",
        "print(f\"Sparse top-k attention compute cost (approx): {sparse_attention_cost}\")\n",
        "print(f\"Compute savings factor: {full_attention_cost / sparse_attention_cost:.2f}x\")\n",
        "\n",
        "# Simulate sparse attention by selecting top_k keys for each query (random for simulation)\n",
        "attention_output = np.zeros((seq_len, feature_dim))\n",
        "for i in range(seq_len):\n",
        "    # Random top_k indices (simulate sparse attention)\n",
        "    top_indices = np.random.choice(seq_len, top_k, replace=False)\n",
        "    # Simple dot product attention weights (unnormalized for simplicity)\n",
        "    attn_weights = np.dot(queries[i], keys[top_indices].T)\n",
        "    attn_weights = attn_weights / np.sum(attn_weights)  # normalize weights\n",
        "    # Weighted sum of values\n",
        "    attention_output[i] = np.sum(attn_weights[:, None] * values[top_indices], axis=0)\n",
        "\n",
        "print(f\"Sparse attention output shape: {attention_output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfsl69tvS-oK",
        "outputId": "53f59268-d9cc-48b9-9e3b-f1c395e9b66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full attention compute cost (approx): 64000000\n",
            "Sparse top-k attention compute cost (approx): 1280000\n",
            "Compute savings factor: 50.00x\n",
            "Sparse attention output shape: (1000, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Mechanism Works:**\n",
        "*The simulation shows that using just the top-k keys (instead of all keys) to calculate attention still produces meaningful output vectors — so you’re not just throwing away all context, but selectively focusing on the important part*"
      ],
      "metadata": {
        "id": "w4RnXW-8TaZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def top_k_attention_sim(query, keys, values, k=8):\n",
        "    # Compute similarity scores between query and all keys\n",
        "    scores = np.dot(query, keys.T)\n",
        "\n",
        "    # Select indices of top-k scores for each query vector\n",
        "    top_k_indices = np.argsort(scores, axis=1)[:, -k:]\n",
        "\n",
        "    # Prepare output array\n",
        "    output = np.zeros((query.shape[0], values.shape[1]))\n",
        "\n",
        "    for i in range(query.shape[0]):\n",
        "        # Get top-k scores and corresponding values for this query\n",
        "        top_scores = scores[i, top_k_indices[i]]\n",
        "        top_values = values[top_k_indices[i]]\n",
        "\n",
        "        # Compute softmax over top-k scores\n",
        "        exp_scores = np.exp(top_scores - np.max(top_scores))\n",
        "        weights = exp_scores / np.sum(exp_scores)\n",
        "\n",
        "        # Weighted sum of top-k values\n",
        "        output[i] = np.sum(weights[:, None] * top_values, axis=0)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Random data setup\n",
        "np.random.seed(42)\n",
        "batch_size = 10\n",
        "dim = 16\n",
        "seq_len = 100\n",
        "\n",
        "query = np.random.rand(batch_size, dim)\n",
        "keys = np.random.rand(seq_len, dim)\n",
        "values = np.random.rand(seq_len, dim)\n",
        "\n",
        "# Run top-k attention\n",
        "output = top_k_attention_sim(query, keys, values, k=8)\n",
        "\n",
        "print(\"Top-k Sparse Attention Output shape:\", output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc9XDbXRTgq0",
        "outputId": "d3d8ee10-75a3-4256-c7d3-3cd39260e368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-k Sparse Attention Output shape: (10, 16)\n",
            "[[0.60303368 0.51685187 0.46938775 0.3976245  0.69321965 0.49889856\n",
            "  0.37053369 0.49768756 0.56680835 0.49585476 0.53343417 0.57378574\n",
            "  0.4896561  0.56861769 0.63927413 0.42866431]\n",
            " [0.57249709 0.37542033 0.50893467 0.39179353 0.62033272 0.52434341\n",
            "  0.47697787 0.37792805 0.58536806 0.59168606 0.47436621 0.48160239\n",
            "  0.64728574 0.49141284 0.51529295 0.51248826]\n",
            " [0.58958451 0.38264895 0.46182021 0.36067372 0.48364336 0.53844097\n",
            "  0.4580881  0.50080268 0.50811448 0.50968576 0.63595995 0.54732521\n",
            "  0.60339384 0.43934444 0.47353965 0.40629289]\n",
            " [0.57535236 0.39514561 0.57379574 0.27054427 0.48334262 0.52258679\n",
            "  0.47879495 0.4122078  0.56253992 0.52440473 0.689449   0.52758776\n",
            "  0.57096321 0.53878252 0.43605923 0.5669418 ]\n",
            " [0.45788774 0.5753652  0.60170536 0.4235399  0.39958919 0.40474891\n",
            "  0.42345218 0.45949806 0.57901847 0.55640587 0.73412555 0.44439554\n",
            "  0.71493371 0.51917007 0.43465956 0.44445001]\n",
            " [0.43919524 0.48811501 0.62455197 0.40804181 0.64499025 0.53114086\n",
            "  0.31582461 0.35469419 0.73907616 0.49927747 0.52630668 0.47565888\n",
            "  0.6328091  0.50910959 0.50502029 0.46039972]\n",
            " [0.46952256 0.3577844  0.48062122 0.50012966 0.63229941 0.46964906\n",
            "  0.28936361 0.33797237 0.83109332 0.54793931 0.47845332 0.53561691\n",
            "  0.61130182 0.55571781 0.59861128 0.41453167]\n",
            " [0.5417594  0.43709261 0.56068245 0.27146589 0.50031952 0.55967072\n",
            "  0.42726825 0.36529488 0.49900455 0.53165064 0.499091   0.56134306\n",
            "  0.68292244 0.49224647 0.46131124 0.52471901]\n",
            " [0.48735232 0.47496092 0.56190095 0.48164652 0.48563222 0.49244854\n",
            "  0.40180733 0.31922991 0.59245826 0.40816259 0.71598873 0.37503689\n",
            "  0.56463981 0.40340528 0.46669905 0.37921755]\n",
            " [0.52932105 0.45526754 0.47031301 0.37843836 0.57873901 0.56145689\n",
            "  0.40626035 0.41707655 0.63313531 0.46456034 0.53998103 0.43470088\n",
            "  0.5340054  0.50472409 0.40808117 0.50083203]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Foundation for Scaling:**\n",
        "*This small, simple simulation is a proof of concept that sparse attention can be implemented and can work on random data, before scaling it to real-world use cases or bigger models.*"
      ],
      "metadata": {
        "id": "9BQPzKQyUZsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sparse_attention_simulation(seq_len=100, embed_dim=64, top_k=10):\n",
        "    # Generate random query, key, value vectors\n",
        "    Q = np.random.rand(seq_len, embed_dim)\n",
        "    K = np.random.rand(seq_len, embed_dim)\n",
        "    V = np.random.rand(seq_len, embed_dim)\n",
        "\n",
        "    # Compute dot product attention scores: Q x K^T\n",
        "    scores = np.dot(Q, K.T)\n",
        "\n",
        "    # For each query vector, pick indices of top_k highest scores\n",
        "    top_k_indices = np.argsort(scores, axis=1)[:, -top_k:]\n",
        "\n",
        "    # Initialize output matrix\n",
        "    output = np.zeros((seq_len, embed_dim))\n",
        "\n",
        "    # Compute sparse attention output: only over top_k keys\n",
        "    for i in range(seq_len):\n",
        "        selected_keys = K[top_k_indices[i]]\n",
        "        selected_values = V[top_k_indices[i]]\n",
        "\n",
        "        # Compute attention weights\n",
        "        attn_scores = np.dot(Q[i], selected_keys.T)\n",
        "        attn_weights = np.exp(attn_scores) / np.sum(np.exp(attn_scores))\n",
        "\n",
        "        # Weighted sum of values\n",
        "        output[i] = np.sum(attn_weights[:, None] * selected_values, axis=0)\n",
        "\n",
        "    print(f\"Sparse attention output shape: {output.shape}\")\n",
        "    return output\n",
        "\n",
        "# Run simulation\n",
        "output = sparse_attention_simulation(seq_len=100, embed_dim=64, top_k=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXd0FSHGUdTd",
        "outputId": "8a5be2a4-b60d-45a5-bb15-bfa7862fea81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparse attention output shape: (100, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory Compression Simulation"
      ],
      "metadata": {
        "id": "7mva7e_UVpvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This step simulates how Cerebra reduces memory usage by compressing keys and values into smaller summaries, instead of storing all token information fully. It shows how memory and compute costs drop while keeping attention effective.**"
      ],
      "metadata": {
        "id": "nUCSjqy9VwAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compress_memory(keys, values, compression_factor=4):\n",
        "    # Compress keys and values by averaging chunks of size compression_factor\n",
        "    def compress(arr):\n",
        "        n = arr.shape[0]\n",
        "        compressed_len = n // compression_factor\n",
        "        compressed = arr[:compressed_len*compression_factor].reshape(compressed_len, compression_factor, -1).mean(axis=1)\n",
        "        return compressed\n",
        "\n",
        "    compressed_keys = compress(keys)\n",
        "    compressed_values = compress(values)\n",
        "    return compressed_keys, compressed_values\n",
        "\n",
        "# Random data\n",
        "seq_len = 1000\n",
        "dim = 64\n",
        "\n",
        "np.random.seed(42)\n",
        "keys = np.random.rand(seq_len, dim)\n",
        "values = np.random.rand(seq_len, dim)\n",
        "\n",
        "print(f\"Original keys shape: {keys.shape}\")\n",
        "print(f\"Original values shape: {values.shape}\")\n",
        "\n",
        "# Compress keys and values\n",
        "compressed_keys, compressed_values = compress_memory(keys, values)\n",
        "\n",
        "print(f\"Compressed keys shape: {compressed_keys.shape}\")\n",
        "print(f\"Compressed values shape: {compressed_values.shape}\")\n",
        "\n",
        "# Simple attention function using compressed memory\n",
        "def attention(query, keys, values):\n",
        "    scores = np.dot(keys, query.T)\n",
        "    weights = np.exp(scores - np.max(scores))\n",
        "    weights /= np.sum(weights)\n",
        "    output = np.dot(weights, values)\n",
        "    return output\n",
        "\n",
        "# Example query vector\n",
        "query = np.random.rand(dim)\n",
        "\n",
        "# Attention output using compressed memory\n",
        "output = attention(query, compressed_keys, compressed_values)\n",
        "print(\"Attention output shape:\", output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SszKMa9aV4Ha",
        "outputId": "1c8772a4-e53d-488e-bf93-72a63a31b60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original keys shape: (1000, 64)\n",
            "Original values shape: (1000, 64)\n",
            "Compressed keys shape: (250, 64)\n",
            "Compressed values shape: (250, 64)\n",
            "Attention output shape: (64,)\n",
            "[0.4955417  0.50172638 0.49840952 0.49366493 0.50558909 0.51304834\n",
            " 0.49213316 0.50773405 0.49200677 0.50023707 0.49289312 0.49282108\n",
            " 0.51625081 0.49592373 0.49926124 0.51989408 0.49814618 0.50114292\n",
            " 0.49528215 0.50686353 0.50503762 0.49227476 0.51723301 0.49451166\n",
            " 0.49323904 0.50214412 0.50879766 0.50442005 0.50104904 0.50902533\n",
            " 0.49540387 0.49542283 0.50760988 0.49635727 0.49579694 0.50808379\n",
            " 0.48592666 0.49361705 0.49874908 0.50073361 0.49984209 0.50334909\n",
            " 0.50226851 0.49994906 0.48911139 0.50755738 0.49207571 0.4953487\n",
            " 0.49657286 0.48686015 0.48836668 0.48969878 0.48642439 0.49372423\n",
            " 0.49620599 0.50458939 0.50047446 0.51418964 0.49886806 0.5177711\n",
            " 0.50554011 0.482335   0.48639424 0.50426473]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integration of Sparse Attention with Memory Compression"
      ],
      "metadata": {
        "id": "gQq-PIOJWU5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This step combines the sparse top-k attention mechanism with the memory compression module into a single function. It simulates the full Cerebra core attention block by first compressing keys and values, then performing sparse attention on the compressed representations. This setup prepares the architecture for eventual training on real datasets by validating that the combined mechanism outputs stable, meaningful attention vectors.**"
      ],
      "metadata": {
        "id": "9zRNuy3JWb81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compress_memory(keys, values, compression_ratio=0.25):\n",
        "    \"\"\"\n",
        "    Compress keys and values by averaging fixed-size blocks.\n",
        "    Args:\n",
        "        keys: (n, d) numpy array\n",
        "        values: (n, d) numpy array\n",
        "        compression_ratio: fraction of original sequence length to keep\n",
        "    Returns:\n",
        "        compressed_keys: (m, d)\n",
        "        compressed_values: (m, d)\n",
        "    \"\"\"\n",
        "    n, d = keys.shape\n",
        "    m = int(n * compression_ratio)\n",
        "    block_size = n // m\n",
        "\n",
        "    compressed_keys = np.array([keys[i*block_size:(i+1)*block_size].mean(axis=0) for i in range(m)])\n",
        "    compressed_values = np.array([values[i*block_size:(i+1)*block_size].mean(axis=0) for i in range(m)])\n",
        "\n",
        "    return compressed_keys, compressed_values\n",
        "\n",
        "def sparse_topk_attention(query, keys, values, k=50):\n",
        "    \"\"\"\n",
        "    Compute attention output for a single query vector attending only to top-k keys.\n",
        "    Args:\n",
        "        query: (d,) numpy array\n",
        "        keys: (m, d) numpy array (compressed)\n",
        "        values: (m, d) numpy array (compressed)\n",
        "        k: number of top keys to attend to\n",
        "    Returns:\n",
        "        output: (d,) numpy array\n",
        "    \"\"\"\n",
        "    # Calculate similarity (dot product)\n",
        "    scores = keys @ query\n",
        "    topk_indices = np.argpartition(scores, -k)[-k:]\n",
        "\n",
        "    # Select top-k keys and values\n",
        "    selected_keys = keys[topk_indices]\n",
        "    selected_values = values[topk_indices]\n",
        "\n",
        "    # Compute scaled dot-product attention\n",
        "    d = query.shape[0]\n",
        "    scores_topk = selected_keys @ query / np.sqrt(d)\n",
        "    weights = np.exp(scores_topk - np.max(scores_topk))\n",
        "    weights /= weights.sum()\n",
        "\n",
        "    # Weighted sum of values\n",
        "    output = weights @ selected_values\n",
        "\n",
        "    return output\n",
        "\n",
        "def cerebra_attention_block(query, keys, values, compression_ratio=0.25, k=50):\n",
        "    \"\"\"\n",
        "    Full Cerebra attention block combining memory compression and sparse attention.\n",
        "    Args:\n",
        "        query: (d,) numpy array\n",
        "        keys: (n, d) numpy array\n",
        "        values: (n, d) numpy array\n",
        "        compression_ratio: fraction for memory compression\n",
        "        k: top-k keys to attend\n",
        "    Returns:\n",
        "        output: (d,) numpy array\n",
        "    \"\"\"\n",
        "    compressed_keys, compressed_values = compress_memory(keys, values, compression_ratio)\n",
        "    output = sparse_topk_attention(query, compressed_keys, compressed_values, k)\n",
        "    return output\n",
        "\n",
        "# Example usage with random data\n",
        "np.random.seed(42)\n",
        "n = 1000  # original sequence length\n",
        "d = 64    # embedding dimension\n",
        "\n",
        "keys = np.random.rand(n, d)\n",
        "values = np.random.rand(n, d)\n",
        "query = np.random.rand(d)\n",
        "\n",
        "output = cerebra_attention_block(query, keys, values, compression_ratio=0.25, k=50)\n",
        "print(\"Cerebra Attention Output shape:\", output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtzkjxqvWgdr",
        "outputId": "94f43a90-c04c-4ebb-a5c2-1d3c1e5c3ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cerebra Attention Output shape: (64,)\n",
            "[0.50835332 0.49829161 0.50259337 0.49768933 0.5010805  0.50655833\n",
            " 0.48847327 0.50623174 0.48429478 0.50550892 0.52147468 0.47992228\n",
            " 0.51311636 0.4999651  0.50466047 0.53183061 0.51458164 0.48388766\n",
            " 0.49607934 0.51294411 0.50256001 0.50713294 0.49602832 0.4923581\n",
            " 0.50961432 0.51137339 0.51841575 0.51656983 0.48068761 0.49783343\n",
            " 0.4810134  0.49826143 0.50932392 0.50938031 0.52264044 0.52008647\n",
            " 0.49044083 0.48597044 0.47451843 0.51254963 0.50491504 0.48601835\n",
            " 0.49799597 0.51234484 0.47688156 0.49481286 0.48348251 0.49788979\n",
            " 0.49702392 0.45054163 0.47822652 0.50132552 0.48049398 0.49704402\n",
            " 0.51245416 0.47963381 0.4950352  0.52844533 0.49807248 0.52571656\n",
            " 0.52342048 0.4779868  0.46315632 0.51101267]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini Training Loop for Cerebra Sparse Attention"
      ],
      "metadata": {
        "id": "A7idTEleWzSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What it does:\n",
        "Trains a tiny model using the Cerebra sparse attention block on synthetic data. This tests whether the sparse, compressed attention can actually learn and improve on a simple task, compared to just randomly outputting vectors. Basically, it’s a proof-of-training-concept for the architecture.**"
      ],
      "metadata": {
        "id": "2ORqHSNzW1Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full fixed script — Cerebra mini training with robust padding/reshape logic\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# determinism for debugging\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class CerebraAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, compression_ratio=0.25):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.compression_ratio = float(compression_ratio)\n",
        "        # compressors keep embed_dim -> embed_dim (simple)\n",
        "        self.key_compressor = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value_compressor = nn.Linear(embed_dim, embed_dim)\n",
        "        self.query_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"\n",
        "        queries: [batch, embed_dim]\n",
        "        keys:    [batch, seq_len, embed_dim]\n",
        "        values:  [batch, seq_len, embed_dim]\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, embed_dim = keys.shape\n",
        "        assert embed_dim == self.embed_dim\n",
        "\n",
        "        # Determine compressed_seq_len using ceiling to avoid fractional loss\n",
        "        compressed_seq_len = max(1, math.ceil(seq_len * self.compression_ratio))\n",
        "        # block_size is the ceil of seq_len / compressed_seq_len\n",
        "        block_size = math.ceil(seq_len / compressed_seq_len)\n",
        "\n",
        "        # padded_seq_len = block_size * compressed_seq_len (guaranteed multiple)\n",
        "        padded_seq_len = block_size * compressed_seq_len\n",
        "        pad_len = padded_seq_len - seq_len  # >= 0\n",
        "\n",
        "        # pad along sequence dimension if needed (pad last tokens)\n",
        "        if pad_len > 0:\n",
        "            # pad format for F.pad on 3D: (pad_last_dim_left, pad_last_dim_right, pad_mid_left, pad_mid_right, ...)\n",
        "            # we need to pad dimension 1 (seq_len). F.pad supports only trailing dims, so we reshape to (batch, embed_dim, seq_len) or use simpler:\n",
        "            keys = F.pad(keys, (0, 0, 0, pad_len))    # pad (seq_len dim) on the right\n",
        "            values = F.pad(values, (0, 0, 0, pad_len))\n",
        "\n",
        "        # Now keys, values shape: [batch, padded_seq_len, embed_dim] and padded_seq_len == block_size * compressed_seq_len\n",
        "\n",
        "        # Flatten for linear compression, apply compressor, then reshape back\n",
        "        # keys_flat shape: [batch * padded_seq_len, embed_dim]\n",
        "        keys_flat = keys.contiguous().view(-1, embed_dim)\n",
        "        values_flat = values.contiguous().view(-1, embed_dim)\n",
        "\n",
        "        comp_keys_flat = self.key_compressor(keys_flat)      # [batch*padded_seq_len, embed_dim]\n",
        "        comp_vals_flat = self.value_compressor(values_flat)\n",
        "\n",
        "        # reshape to [batch, padded_seq_len, embed_dim]\n",
        "        comp_keys = comp_keys_flat.view(batch_size, padded_seq_len, embed_dim)\n",
        "        comp_vals = comp_vals_flat.view(batch_size, padded_seq_len, embed_dim)\n",
        "\n",
        "        # Now group into blocks and average to compress: shape -> [batch, compressed_seq_len, block_size, embed_dim]\n",
        "        comp_keys = comp_keys.view(batch_size, compressed_seq_len, block_size, embed_dim).mean(dim=2)   # [batch, compressed_seq_len, embed_dim]\n",
        "        comp_vals = comp_vals.view(batch_size, compressed_seq_len, block_size, embed_dim).mean(dim=2)   # [batch, compressed_seq_len, embed_dim]\n",
        "\n",
        "        # Project queries and compute attention\n",
        "        proj_q = self.query_proj(queries).unsqueeze(1)   # [batch, 1, embed_dim]\n",
        "        # comp_keys.transpose(1,2): [batch, embed_dim, compressed_seq_len]\n",
        "        scores = torch.matmul(proj_q, comp_keys.transpose(1, 2)).squeeze(1)  # [batch, compressed_seq_len]\n",
        "        attn = torch.softmax(scores / math.sqrt(self.embed_dim), dim=-1)    # [batch, compressed_seq_len]\n",
        "\n",
        "        # Weighted sum of compressed values\n",
        "        out = torch.matmul(attn.unsqueeze(1), comp_vals).squeeze(1)  # [batch, embed_dim]\n",
        "        return out\n",
        "\n",
        "\n",
        "class CerebraModel(nn.Module):\n",
        "    def __init__(self, embed_dim=64, seq_len=50, compression_ratio=0.25):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.attn = CerebraAttention(embed_dim, compression_ratio=compression_ratio)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embed_dim, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch, seq_len, embed_dim]\n",
        "        queries = x[:, 0, :]   # use first token as query (demo)\n",
        "        keys = x\n",
        "        values = x\n",
        "        attn_out = self.attn(queries, keys, values)\n",
        "        logits = self.classifier(attn_out)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ------- Data helper: patterned data so model can learn -------\n",
        "def generate_patterned_data(batch_size, seq_len, embed_dim):\n",
        "    \"\"\"\n",
        "    Create a dataset with clear pattern:\n",
        "    - class 0: sequences have negative bias\n",
        "    - class 1: sequences have positive bias\n",
        "    This is learnable and should get high accuracy.\n",
        "    \"\"\"\n",
        "    X = torch.randn(batch_size, seq_len, embed_dim, device=DEVICE) * 0.1\n",
        "    y = torch.randint(0, 2, (batch_size,), device=DEVICE)\n",
        "    # Add class signal\n",
        "    # Use first few tokens stronger signal to be picked by query at position 0\n",
        "    for i in range(batch_size):\n",
        "        if y[i] == 0:\n",
        "            X[i] -= 1.0  # shift whole sequence downward\n",
        "        else:\n",
        "            X[i] += 1.0  # shift upward\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# ------- Training loop -------\n",
        "def train(model, epochs=30, batch_size=64, seq_len=50, embed_dim=64, lr=5e-3, compression_ratio=0.25):\n",
        "    model.to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        X, y = generate_patterned_data(batch_size, seq_len, embed_dim)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 2 == 0 or epoch == 1:\n",
        "            with torch.no_grad():\n",
        "                pred = outputs.argmax(dim=1)\n",
        "                acc = (pred == y).float().mean().item()\n",
        "            print(f\"Epoch {epoch}/{epochs} - Loss: {loss.item():.4f} - Acc: {acc*100:.2f}%\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Run the training\n",
        "if __name__ == \"__main__\":\n",
        "    EMBED = 64\n",
        "    SEQ = 50\n",
        "    BATCH = 64\n",
        "    model = CerebraModel(embed_dim=EMBED, seq_len=SEQ, compression_ratio=0.25)\n",
        "    trained = train(model, epochs=30, batch_size=BATCH, seq_len=SEQ, embed_dim=EMBED, lr=0.005, compression_ratio=0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbrBDxQKW5jJ",
        "outputId": "886874ab-a383-4a12-d224-7894ea21a6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Loss: 0.4371 - Acc: 100.00%\n",
            "Epoch 2/30 - Loss: 0.1910 - Acc: 100.00%\n",
            "Epoch 4/30 - Loss: 0.0319 - Acc: 100.00%\n",
            "Epoch 6/30 - Loss: 0.0041 - Acc: 100.00%\n",
            "Epoch 8/30 - Loss: 0.0007 - Acc: 100.00%\n",
            "Epoch 10/30 - Loss: 0.0001 - Acc: 100.00%\n",
            "Epoch 12/30 - Loss: 0.0000 - Acc: 100.00%\n",
            "Epoch 14/30 - Loss: 0.0000 - Acc: 100.00%\n",
            "Epoch 16/30 - Loss: 0.0000 - Acc: 100.00%\n",
            "Epoch 18/30 - Loss: 0.0000 - Acc: 100.00%\n",
            "Epoch 20/30 - Loss: 0.0000 - Acc: 100.00%\n",
            "Epoch 22/30 - Loss: 0.0000 - Acc: 100.00%\n",
            "Epoch 24/30 - Loss: 0.0000 - Acc: 100.00%\n",
            "Epoch 26/30 - Loss: 0.0000 - Acc: 100.00%\n",
            "Epoch 28/30 - Loss: 0.0000 - Acc: 100.00%\n",
            "Epoch 30/30 - Loss: 0.0000 - Acc: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Cerebra on a Dataset"
      ],
      "metadata": {
        "id": "ynROSmHdK-Rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Load & Preprocess Dataset**\n",
        "*Description:\n",
        "Load the CSV file, encode categorical country data into numeric embeddings, normalize numeric features (Employee age, Employee work exp), and prepare the dataset for model training by splitting into train/test sets. This step ensures the data is in the right format for the Cerebra model to learn effectively.*"
      ],
      "metadata": {
        "id": "oKzyFhOjLE-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('employee_dataset_15k_full.csv')\n",
        "\n",
        "# Quick check for missing values and drop if any (clean data is a must)\n",
        "if df.isnull().sum().sum() > 0:\n",
        "    print(f\"Warning: Found missing values, dropping rows with nulls...\")\n",
        "    df = df.dropna()\n",
        "\n",
        "# Encode 'country' into numeric labels\n",
        "le_country = LabelEncoder()\n",
        "df['country_encoded'] = le_country.fit_transform(df['country'])\n",
        "\n",
        "# Normalize numeric features for better training stability\n",
        "scaler = StandardScaler()\n",
        "df[['Employee age', 'Emplyoee work exp']] = scaler.fit_transform(df[['Employee age', 'Emplyoee work exp']])\n",
        "\n",
        "# Prepare features and target (salary)\n",
        "features = df[['country_encoded', 'Employee age', 'Emplyoee work exp']].values\n",
        "targets = df['Salary'].values.astype(np.float32)\n",
        "\n",
        "# Split into train (80%) and test (20%) sets with shuffle & fixed seed for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "# Custom PyTorch Dataset to wrap features & targets\n",
        "class SalaryDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # (N, 1) for regression target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Create DataLoaders for batching & shuffling during training\n",
        "train_dataset = SalaryDataset(X_train, y_train)\n",
        "test_dataset = SalaryDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
        "print(f\"Sample feature vector shape: {train_dataset[0][0].shape}, Sample target shape: {train_dataset[0][1].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqHetTzMLOYv",
        "outputId": "93f65f80-81b3-42e4-eff9-eef9819d45ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 12000, Test samples: 3000\n",
            "Sample feature vector shape: torch.Size([3]), Sample target shape: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build and Train Cerebra Model for Salary Prediction**\n",
        "*Description:\n",
        "In this step, we create a Cerebra attention-based regression model to predict employee salaries using the preprocessed features. We then train this model on the training dataset, monitor loss during training, and prepare for evaluation.*"
      ],
      "metadata": {
        "id": "dQNESxOrMrA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Cerebra Attention block for regression\n",
        "class CerebraAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, compression_ratio=0.25):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.compression_ratio = compression_ratio\n",
        "        compressed_dim = max(1, int(embed_dim * compression_ratio))\n",
        "        self.compressed_dim = compressed_dim\n",
        "\n",
        "        self.key_compressor = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value_compressor = nn.Linear(embed_dim, embed_dim)\n",
        "        self.query_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        batch_size, seq_len, embed_dim = keys.shape\n",
        "\n",
        "        proj_queries = self.query_proj(queries)  # [batch_size, embed_dim]\n",
        "\n",
        "        compressed_keys = self.key_compressor(keys.view(-1, embed_dim)).view(batch_size, seq_len, embed_dim)\n",
        "        compressed_values = self.value_compressor(values.view(-1, embed_dim)).view(batch_size, seq_len, embed_dim)\n",
        "\n",
        "        compressed_seq_len = max(1, int(seq_len * self.compression_ratio))\n",
        "        block_size = seq_len // compressed_seq_len\n",
        "\n",
        "        padding = (block_size * compressed_seq_len) - seq_len\n",
        "        if padding > 0:\n",
        "            compressed_keys = torch.nn.functional.pad(compressed_keys, (0,0,0,padding))\n",
        "            compressed_values = torch.nn.functional.pad(compressed_values, (0,0,0,padding))\n",
        "            seq_len = compressed_keys.shape[1]\n",
        "\n",
        "        block_size = seq_len // compressed_seq_len\n",
        "\n",
        "        compressed_keys = compressed_keys.view(batch_size, compressed_seq_len, block_size, embed_dim).mean(dim=2)\n",
        "        compressed_values = compressed_values.view(batch_size, compressed_seq_len, block_size, embed_dim).mean(dim=2)\n",
        "\n",
        "        # Compute attention scores\n",
        "        scores = torch.matmul(proj_queries.unsqueeze(1), compressed_keys.transpose(1, 2)).squeeze(1)\n",
        "        attn_weights = torch.softmax(scores, dim=-1)  # [batch_size, compressed_seq_len]\n",
        "\n",
        "        output = torch.matmul(attn_weights.unsqueeze(1), compressed_values).squeeze(1)  # [batch_size, embed_dim]\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# Cerebra Model for regression\n",
        "class CerebraRegressionModel(nn.Module):\n",
        "    def __init__(self, embed_dim=3, seq_len=1):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        self.attn = CerebraAttention(embed_dim)\n",
        "        self.regressor = nn.Linear(embed_dim, 1)  # output salary prediction\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch_size, seq_len, embed_dim]\n",
        "        # We treat the whole input as keys and values, and query is the first token for demo\n",
        "        queries = x[:, 0, :]  # [batch_size, embed_dim]\n",
        "        keys = x\n",
        "        values = x\n",
        "        attn_output = self.attn(queries, keys, values)  # [batch_size, embed_dim]\n",
        "        output = self.regressor(attn_output)  # [batch_size, 1]\n",
        "        return output.squeeze(1)  # [batch_size]\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_regression_model(model, train_loader, val_loader, epochs=30, lr=0.001):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for features, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(features)\n",
        "            loss = criterion(preds, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * features.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for features, targets in val_loader:\n",
        "                preds = model(features)\n",
        "                loss = criterion(preds, targets)\n",
        "                val_loss += loss.item() * features.size(0)\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Train MSE: {train_loss:.4f} - Val MSE: {val_loss:.4f}\")\n",
        "\n",
        "# Example of dataset loaders (you'll replace this with your actual dataset loaders)\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Assume train_features, train_targets, val_features, val_targets are torch tensors from your preprocessed data\n",
        "\n",
        "# Example:\n",
        "# train_dataset = TensorDataset(train_features, train_targets)\n",
        "# val_dataset = TensorDataset(val_features, val_targets)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "\n",
        "# model = CerebraRegressionModel(embed_dim=3, seq_len=1)\n",
        "# train_regression_model(model, train_loader, val_loader)\n"
      ],
      "metadata": {
        "id": "a3WclYxcM4aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Model and Implement CLI Prediction Interface**\n",
        "Description:\n",
        "*After training, we evaluate model performance on test data and implement a clean command-line interface (CLI) that asks users questions (Country, Employee Age, Work Experience) and predicts salary based on inputs using the trained Cerebra model.*"
      ],
      "metadata": {
        "id": "VvGcC2WONWMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Cerebra -- Single-file Stable Script\n",
        "- Minimal, fully working Cerebra training + CLI prediction script\n",
        "- No argparse (so no SystemExit:2). Uses safe defaults and the provided CSV filename.\n",
        "- Trains on log1p(salary) target and predicts salary (real scale) in CLI.\n",
        "- Saves model and preprocessors (label encoder + scaler + val_rmse) to disk.\n",
        "- CLI shows confidence bar and short comparison text explaining why Cerebra's result is efficient vs Transformers / RNN / CNN / Mamba for this task.\n",
        "\n",
        "Instructions:\n",
        "1) Put `employee_dataset_15k_full.csv` in the same folder.\n",
        "2) Run `python cerebra_cli.py` (or run in Colab). It will train and then drop into the CLI.\n",
        "3) Type country names exactly as in your CSV (case-sensitive); type 'exit' to quit.\n",
        "\n",
        "Author: ACE (ChatGPT for Shaheer)\n",
        "Date: 2025-08-10\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import pickle\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.optim as optim\n",
        "\n",
        "# --------------------\n",
        "# Config\n",
        "# --------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    seed: int = 42\n",
        "    data_path: str = 'employee_dataset_15k_full.csv'\n",
        "    batch_size: int = 256\n",
        "    epochs: int = 30\n",
        "    lr: float = 1e-3\n",
        "    emb_dim: int = 32\n",
        "    compression_ratio: float = 0.5\n",
        "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    num_workers: int = 0\n",
        "    model_path: str = 'cerebra_minimal.pth'\n",
        "    preproc_path: str = 'cerebra_preproc.pkl'\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# --------------------\n",
        "# Utilities\n",
        "# --------------------\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def load_csv(path: str) -> pd.DataFrame:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"CSV not found at {path}. Put your file there or change cfg.data_path\")\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    # normalize column names to expected keys\n",
        "    # expect: country, Employee age, Emplyoee work exp, Salary\n",
        "    expected = ['country', 'Employee age', 'Emplyoee work exp', 'Salary']\n",
        "    for e in expected:\n",
        "        if e not in df.columns:\n",
        "            raise ValueError(f\"CSV missing expected column: {e}\")\n",
        "    return df\n",
        "\n",
        "# --------------------\n",
        "# Preprocessing & Dataset\n",
        "# --------------------\n",
        "class SalaryDataset(Dataset):\n",
        "    def __init__(self, df, le: LabelEncoder, scaler: StandardScaler, target_log=True):\n",
        "        self.le = le\n",
        "        self.scaler = scaler\n",
        "        self.target_log = target_log\n",
        "        self.country = le.transform(df['country'].astype(str)).astype(np.int64)\n",
        "        self.num = scaler.transform(df[['Employee age', 'Emplyoee work exp']].values.astype(np.float32))\n",
        "        y = df['Salary'].values.astype(np.float32)\n",
        "        if self.target_log:\n",
        "            y = np.log1p(y)\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = np.array([self.country[idx], self.num[idx,0], self.num[idx,1]], dtype=np.float32)\n",
        "        return torch.from_numpy(x), torch.tensor(self.y[idx], dtype=torch.float32)\n",
        "\n",
        "\n",
        "def build_preprocessors(df):\n",
        "    le = LabelEncoder()\n",
        "    le.fit(df['country'].astype(str))\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(df[['Employee age','Emplyoee work exp']].values.astype(np.float32))\n",
        "    return le, scaler\n",
        "\n",
        "# --------------------\n",
        "# Cerebra building blocks\n",
        "# --------------------\n",
        "class FeatureTokenizer(nn.Module):\n",
        "    def __init__(self, num_countries: int, emb_dim: int = 32):\n",
        "        super().__init__()\n",
        "        self.country_emb = nn.Embedding(num_countries, emb_dim)\n",
        "        self.age_proj = nn.Linear(1, emb_dim)\n",
        "        self.exp_proj = nn.Linear(1, emb_dim)\n",
        "        self.pos = nn.Parameter(torch.zeros(3, emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        country = x[:,0].long()\n",
        "        age = x[:,1].unsqueeze(1)\n",
        "        exp = x[:,2].unsqueeze(1)\n",
        "        c = self.country_emb(country)\n",
        "        a = self.age_proj(age)\n",
        "        e = self.exp_proj(exp)\n",
        "        tokens = torch.stack([c, a, e], dim=1)  # [B,3,E]\n",
        "        tokens = tokens + self.pos.unsqueeze(0)\n",
        "        return tokens\n",
        "\n",
        "class CompressedAttention(nn.Module):\n",
        "    def __init__(self, emb_dim:int, comp_ratio:float=0.5):\n",
        "        super().__init__()\n",
        "        self.emb = emb_dim\n",
        "        self.comp_ratio = comp_ratio\n",
        "        self.k_lin = nn.Linear(emb_dim, emb_dim)\n",
        "        self.v_lin = nn.Linear(emb_dim, emb_dim)\n",
        "        self.q_lin = nn.Linear(emb_dim, emb_dim)\n",
        "\n",
        "    def forward(self, q, kv):\n",
        "        # q: [B, E], kv: [B, N, E]\n",
        "        B, N, E = kv.shape\n",
        "        comp_n = max(1, math.ceil(N * self.comp_ratio))\n",
        "        block = math.ceil(N / comp_n)\n",
        "        padded = block * comp_n\n",
        "        pad = padded - N\n",
        "        if pad > 0:\n",
        "            kv = F.pad(kv, (0,0,0,pad))\n",
        "        k = self.k_lin(kv.view(-1, E)).view(B, padded, E)\n",
        "        v = self.v_lin(kv.view(-1, E)).view(B, padded, E)\n",
        "        k = k.view(B, comp_n, block, E).mean(dim=2)  # [B, comp_n, E]\n",
        "        v = v.view(B, comp_n, block, E).mean(dim=2)  # [B, comp_n, E]\n",
        "        q_proj = self.q_lin(q).unsqueeze(1)  # [B,1,E]\n",
        "        scores = torch.matmul(q_proj, k.transpose(1,2)).squeeze(1) / math.sqrt(E)\n",
        "        w = torch.softmax(scores, dim=-1)\n",
        "        out = torch.matmul(w.unsqueeze(1), v).squeeze(1)\n",
        "        return out\n",
        "\n",
        "class CerebraModel(nn.Module):\n",
        "    def __init__(self, num_countries:int, emb_dim:int=32, comp_ratio:float=0.5):\n",
        "        super().__init__()\n",
        "        self.tokenizer = FeatureTokenizer(num_countries, emb_dim)\n",
        "        self.cls = nn.Parameter(torch.zeros(emb_dim))\n",
        "        self.attn = CompressedAttention(emb_dim, comp_ratio)\n",
        "        self.head = nn.Sequential(nn.LayerNorm(emb_dim), nn.ReLU(), nn.Linear(emb_dim,1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        tok = self.tokenizer(x)  # [B,3,E]\n",
        "        B = tok.shape[0]\n",
        "        q = self.cls.unsqueeze(0).expand(B, -1)\n",
        "        out = self.attn(q, tok)\n",
        "        out = self.head(out).squeeze(1)\n",
        "        return out\n",
        "\n",
        "# --------------------\n",
        "# Training & helpers\n",
        "# --------------------\n",
        "def train_model(model, train_loader, val_loader, cfg):\n",
        "    device = cfg.device\n",
        "    model = model.to(device)\n",
        "    opt = optim.Adam(model.parameters(), lr=cfg.lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(1, cfg.epochs+1):\n",
        "        model.train()\n",
        "        t0 = time.time()\n",
        "        train_losses = []\n",
        "        for Xb, yb in train_loader:\n",
        "            Xb = Xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            out = model(Xb)\n",
        "            loss = loss_fn(out, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            train_losses.append(loss.item())\n",
        "        # val\n",
        "        model.eval()\n",
        "        preds = []\n",
        "        trues = []\n",
        "        with torch.no_grad():\n",
        "            for Xb, yb in val_loader:\n",
        "                Xb = Xb.to(device)\n",
        "                out = model(Xb).cpu().numpy()\n",
        "                preds.append(out)\n",
        "                trues.append(yb.numpy())\n",
        "        preds = np.concatenate(preds)\n",
        "        trues = np.concatenate(trues)\n",
        "        # convert from log-space\n",
        "        preds_raw = np.expm1(preds)\n",
        "        trues_raw = np.expm1(trues)\n",
        "        rmse = math.sqrt(mean_squared_error(trues_raw, preds_raw))\n",
        "        mae = mean_absolute_error(trues_raw, preds_raw)\n",
        "        r2 = r2_score(trues_raw, preds_raw)\n",
        "        print(f\"Epoch {epoch}/{cfg.epochs} - TrainLoss: {np.mean(train_losses):.6f} - Val RMSE: {rmse:.2f} MAE: {mae:.2f} R2: {r2:.4f} - time: {time.time()-t0:.1f}s\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_model(model, loader, cfg):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    trues = []\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            out = model(Xb.to(cfg.device)).cpu().numpy()\n",
        "            preds.append(out)\n",
        "            trues.append(yb.numpy())\n",
        "    preds = np.concatenate(preds)\n",
        "    trues = np.concatenate(trues)\n",
        "    preds_raw = np.expm1(preds)\n",
        "    trues_raw = np.expm1(trues)\n",
        "    return {\n",
        "        'mse': float(mean_squared_error(trues_raw, preds_raw)),\n",
        "        'rmse': float(math.sqrt(mean_squared_error(trues_raw, preds_raw))),\n",
        "        'mae': float(mean_absolute_error(trues_raw, preds_raw)),\n",
        "        'r2': float(r2_score(trues_raw, preds_raw))\n",
        "    }\n",
        "\n",
        "# --------------------\n",
        "# Baselines for context\n",
        "# --------------------\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def train_baselines(df, le, scaler):\n",
        "    arr_country = le.transform(df['country'].astype(str))\n",
        "    arr_num = scaler.transform(df[['Employee age','Emplyoee work exp']].values.astype(np.float32))\n",
        "    X = np.column_stack([arr_country, arr_num])\n",
        "    y = df['Salary'].values.astype(np.float32)\n",
        "    n = len(y)\n",
        "    idx = np.arange(n)\n",
        "    np.random.shuffle(idx)\n",
        "    split = int(0.8*n)\n",
        "    tr, te = idx[:split], idx[split:]\n",
        "    Xtr, Xte = X[tr], X[te]\n",
        "    ytr, yte = y[tr], y[te]\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(Xtr, np.log1p(ytr))\n",
        "    preds = np.expm1(lr.predict(Xte))\n",
        "    lr_rmse = math.sqrt(mean_squared_error(yte, preds))\n",
        "    # small MLP baseline\n",
        "    mlp = nn.Sequential(nn.Linear(Xtr.shape[1],64), nn.ReLU(), nn.Linear(64,1))\n",
        "    opt = optim.Adam(mlp.parameters(), lr=1e-3)\n",
        "    crit = nn.MSELoss()\n",
        "    ytr_log = torch.tensor(np.log1p(ytr), dtype=torch.float32)\n",
        "    Xtr_t = torch.tensor(Xtr, dtype=torch.float32)\n",
        "    for _ in range(200):\n",
        "        opt.zero_grad()\n",
        "        out = mlp(Xtr_t).squeeze(1)\n",
        "        loss = crit(out, ytr_log)\n",
        "        loss.backward(); opt.step()\n",
        "    with torch.no_grad():\n",
        "        preds_mlp = np.expm1(mlp(torch.tensor(Xte, dtype=torch.float32)).numpy().squeeze())\n",
        "    mlp_rmse = math.sqrt(mean_squared_error(yte, preds_mlp))\n",
        "    return {'linear_rmse': lr_rmse, 'mlp_rmse': mlp_rmse}\n",
        "\n",
        "# --------------------\n",
        "# CLI predictor + confidence\n",
        "# --------------------\n",
        "\n",
        "def save_preproc(le, scaler, val_rmse):\n",
        "    with open(cfg.preproc_path, 'wb') as f:\n",
        "        pickle.dump({'le': le, 'scaler': scaler, 'val_rmse': val_rmse}, f)\n",
        "\n",
        "\n",
        "def load_preproc():\n",
        "    if not os.path.exists(cfg.preproc_path):\n",
        "        raise FileNotFoundError('Preprocessor file not found. Train model first.')\n",
        "    with open(cfg.preproc_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data['le'], data['scaler'], data['val_rmse']\n",
        "\n",
        "\n",
        "def confidence_bar(pred_salary, val_rmse):\n",
        "    # Simple heuristic: confidence = 1 - min(val_rmse / pred_salary, 1)\n",
        "    # If RMSE << pred, confidence near 1; if RMSE huge, confidence low.\n",
        "    eps = 1e-6\n",
        "    ratio = min(val_rmse / (pred_salary + eps), 1.0)\n",
        "    conf = 1.0 - ratio\n",
        "    conf = max(0.0, min(conf, 0.999))\n",
        "    bars = 20\n",
        "    filled = int(conf * bars)\n",
        "    return '[' + '#' * filled + '-' * (bars - filled) + ']', conf * 100\n",
        "\n",
        "\n",
        "def approx_flops_forward(emb_dim, N, comp_ratio):\n",
        "    # crude FLOPs estimate for single forward pass in attention: dot products and projections\n",
        "    comp_n = max(1, math.ceil(N * comp_ratio))\n",
        "    # projections k,v per token ~ 2 * emb_dim * N\n",
        "    proj = 2 * emb_dim * N\n",
        "    # compressed attention: comp_n * emb_dim * emb_dim (approx) -> we're simplifying\n",
        "    attn_cost = comp_n * emb_dim * emb_dim\n",
        "    return proj + attn_cost\n",
        "\n",
        "\n",
        "def cli_loop(model):\n",
        "    model.eval()\n",
        "    le, scaler, val_rmse = load_preproc()\n",
        "    device = cfg.device\n",
        "    emb_dim = cfg.emb_dim\n",
        "    countries = list(le.classes_)\n",
        "    print('\\n--- Cerebra CLI (type exit to quit) ---')\n",
        "    print('Example countries:', ', '.join(countries[:10]))\n",
        "    while True:\n",
        "        country = input('Country: ').strip()\n",
        "        if country.lower() == 'exit':\n",
        "            break\n",
        "        if country not in countries:\n",
        "            print('Country not found. Try exact name from dataset. (case sensitive)')\n",
        "            continue\n",
        "        try:\n",
        "            age = float(input('Employee age: ').strip())\n",
        "            exp = float(input('Years of experience: ').strip())\n",
        "        except ValueError:\n",
        "            print('Invalid numbers; try again.')\n",
        "            continue\n",
        "        # preprocess\n",
        "        country_enc = le.transform([country])[0]\n",
        "        # Extract only numerical features for scaling\n",
        "        numerical_features = np.array([age, exp], dtype=float).reshape(1, -1)\n",
        "        features_scaled = scaler.transform(numerical_features)\n",
        "        # Combine encoded country with scaled numerical features\n",
        "        x_tensor = torch.from_numpy(np.array([country_enc, features_scaled[0,0], features_scaled[0,1]], dtype=np.float32))\n",
        "        x_tensor = x_tensor.to(cfg.device)\n",
        "        with torch.no_grad():\n",
        "            pred_log = model(x_tensor.unsqueeze(0)).cpu().item()\n",
        "        pred_real = math.expm1(pred_log)\n",
        "        bar, confpct = confidence_bar(pred_real, val_rmse)\n",
        "        flops = approx_flops_forward(cfg.emb_dim, 3, cfg.compression_ratio)\n",
        "        print(f\"\\nPredicted salary: ${pred_real:,.2f}\")\n",
        "        print(f\"Confidence: {bar}  {confpct:.1f}%\")\n",
        "        print(f\"Estimated forward FLOPs (single sample): ~{int(flops)}\")\n",
        "        # short explanation tailored to this sample\n",
        "        print('\\nWhy Cerebra here?')\n",
        "        print('- Compressed sparse attention keeps compute near-linear for short token sets (3 tokens).')\n",
        "        print('- Transformers have quadratic attention which is unnecessary and slower for tiny inputs.')\n",
        "        print('- RNNs are sequential and give no parallelism advantage for this one-shot prediction.')\n",
        "        print('- CNNs are for spatial patterns (images), not tabular scalar features.')\n",
        "        print('- Mamba/SSM is strong for very long sequences; for 3 tokens its extra complexity gives no advantage.')\n",
        "        print('\\n')\n",
        "\n",
        "# --------------------\n",
        "# Main\n",
        "# --------------------\n",
        "\n",
        "def main():\n",
        "    print('Running Cerebra with config:', cfg)\n",
        "    set_seed(cfg.seed)\n",
        "    df = load_csv(cfg.data_path)\n",
        "    le, scaler = build_preprocessors(df)\n",
        "    dataset = SalaryDataset(df, le, scaler, target_log=True)\n",
        "    n = len(dataset)\n",
        "    idx = np.arange(n)\n",
        "    np.random.shuffle(idx)\n",
        "    split = int(0.8 * n)\n",
        "    train_idx, test_idx = idx[:split], idx[split:]\n",
        "    train_loader = DataLoader(Subset(dataset, train_idx), batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers)\n",
        "    test_loader = DataLoader(Subset(dataset, test_idx), batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
        "\n",
        "    num_countries = len(le.classes_)\n",
        "    model = CerebraModel(num_countries, emb_dim=cfg.emb_dim, comp_ratio=cfg.compression_ratio)\n",
        "    model = train_model(model, train_loader, test_loader, cfg)\n",
        "\n",
        "    metrics = evaluate_model(model, test_loader, cfg)\n",
        "    print('\\nFinal Cerebra metrics:', metrics)\n",
        "\n",
        "    # compute val_rmse on original scale for confidence heuristic\n",
        "    # reuse evaluate_model internal logic quickly\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    trues = []\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in DataLoader(Subset(dataset, test_idx), batch_size=cfg.batch_size):\n",
        "            out = model(Xb.to(cfg.device)).cpu().numpy()\n",
        "            preds.append(out)\n",
        "            trues.append(yb.numpy())\n",
        "    preds = np.concatenate(preds); trues = np.concatenate(trues)\n",
        "    preds_raw = np.expm1(preds); trues_raw = np.expm1(trues)\n",
        "    val_rmse = math.sqrt(mean_squared_error(trues_raw, preds_raw))\n",
        "\n",
        "    # save preprocessors and val_rmse\n",
        "    save_preproc(le, scaler, val_rmse)\n",
        "\n",
        "    print('\\nTraining baselines...')\n",
        "    baselines = train_baselines(df, le, scaler)\n",
        "    print('Baselines:', baselines)\n",
        "\n",
        "    # save model\n",
        "    torch.save(model.state_dict(), cfg.model_path)\n",
        "    print(f'Checkpoint saved: {cfg.model_path}')\n",
        "\n",
        "    # start CLI\n",
        "    cli_loop(model)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E6j3lWcJcepJ",
        "outputId": "0fc4e0e3-f372-4728-e292-26a0c2800fbf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Cerebra with config: Config(seed=42, data_path='employee_dataset_15k_full.csv', batch_size=256, epochs=30, lr=0.001, emb_dim=32, compression_ratio=0.5, device='cuda', num_workers=0, model_path='cerebra_minimal.pth', preproc_path='cerebra_preproc.pkl')\n",
            "Epoch 1/30 - TrainLoss: 101.329927 - Val RMSE: 100482.65 MAE: 94281.96 R2: -7.3609 - time: 0.3s\n",
            "Epoch 2/30 - TrainLoss: 64.778325 - Val RMSE: 100436.54 MAE: 94233.10 R2: -7.3533 - time: 0.3s\n",
            "Epoch 3/30 - TrainLoss: 43.007163 - Val RMSE: 100248.83 MAE: 94033.05 R2: -7.3221 - time: 0.3s\n",
            "Epoch 4/30 - TrainLoss: 26.734264 - Val RMSE: 99560.00 MAE: 93298.38 R2: -7.2081 - time: 0.3s\n",
            "Epoch 5/30 - TrainLoss: 15.099806 - Val RMSE: 97276.91 MAE: 90858.08 R2: -6.8360 - time: 0.4s\n",
            "Epoch 6/30 - TrainLoss: 7.499935 - Val RMSE: 91213.09 MAE: 84354.47 R2: -5.8895 - time: 0.3s\n",
            "Epoch 7/30 - TrainLoss: 3.254507 - Val RMSE: 79445.15 MAE: 71684.96 R2: -4.2265 - time: 0.3s\n",
            "Epoch 8/30 - TrainLoss: 1.274666 - Val RMSE: 63778.75 MAE: 55124.59 R2: -2.3684 - time: 0.3s\n",
            "Epoch 9/30 - TrainLoss: 0.515380 - Val RMSE: 49804.29 MAE: 40854.67 R2: -1.0540 - time: 0.3s\n",
            "Epoch 10/30 - TrainLoss: 0.276726 - Val RMSE: 41348.85 MAE: 32721.73 R2: -0.4158 - time: 0.4s\n",
            "Epoch 11/30 - TrainLoss: 0.213842 - Val RMSE: 37669.27 MAE: 29635.62 R2: -0.1750 - time: 0.3s\n",
            "Epoch 12/30 - TrainLoss: 0.194495 - Val RMSE: 35615.82 MAE: 27755.89 R2: -0.0504 - time: 0.3s\n",
            "Epoch 13/30 - TrainLoss: 0.160637 - Val RMSE: 32752.83 MAE: 25848.29 R2: 0.1117 - time: 0.3s\n",
            "Epoch 14/30 - TrainLoss: 0.133315 - Val RMSE: 29830.71 MAE: 23821.59 R2: 0.2631 - time: 0.3s\n",
            "Epoch 15/30 - TrainLoss: 0.118845 - Val RMSE: 27669.61 MAE: 22083.46 R2: 0.3660 - time: 0.3s\n",
            "Epoch 16/30 - TrainLoss: 0.111475 - Val RMSE: 26470.99 MAE: 21245.09 R2: 0.4198 - time: 0.3s\n",
            "Epoch 17/30 - TrainLoss: 0.107374 - Val RMSE: 25669.76 MAE: 20623.30 R2: 0.4543 - time: 0.3s\n",
            "Epoch 18/30 - TrainLoss: 0.103932 - Val RMSE: 24756.49 MAE: 19751.64 R2: 0.4925 - time: 0.3s\n",
            "Epoch 19/30 - TrainLoss: 0.099368 - Val RMSE: 24290.66 MAE: 19594.39 R2: 0.5114 - time: 0.3s\n",
            "Epoch 20/30 - TrainLoss: 0.090851 - Val RMSE: 23004.19 MAE: 18454.11 R2: 0.5618 - time: 0.4s\n",
            "Epoch 21/30 - TrainLoss: 0.077572 - Val RMSE: 21390.85 MAE: 16860.44 R2: 0.6211 - time: 0.5s\n",
            "Epoch 22/30 - TrainLoss: 0.060283 - Val RMSE: 19582.71 MAE: 14881.33 R2: 0.6824 - time: 0.4s\n",
            "Epoch 23/30 - TrainLoss: 0.041023 - Val RMSE: 17138.29 MAE: 12165.29 R2: 0.7568 - time: 0.3s\n",
            "Epoch 24/30 - TrainLoss: 0.028395 - Val RMSE: 15335.60 MAE: 10232.66 R2: 0.8053 - time: 0.3s\n",
            "Epoch 25/30 - TrainLoss: 0.024260 - Val RMSE: 14569.74 MAE: 9493.35 R2: 0.8242 - time: 0.3s\n",
            "Epoch 26/30 - TrainLoss: 0.022968 - Val RMSE: 14201.78 MAE: 9239.54 R2: 0.8330 - time: 0.3s\n",
            "Epoch 27/30 - TrainLoss: 0.022483 - Val RMSE: 13818.71 MAE: 8949.61 R2: 0.8419 - time: 0.3s\n",
            "Epoch 28/30 - TrainLoss: 0.022103 - Val RMSE: 13809.91 MAE: 8922.28 R2: 0.8421 - time: 0.5s\n",
            "Epoch 29/30 - TrainLoss: 0.021732 - Val RMSE: 13597.25 MAE: 8722.12 R2: 0.8469 - time: 0.5s\n",
            "Epoch 30/30 - TrainLoss: 0.021376 - Val RMSE: 13260.60 MAE: 8525.08 R2: 0.8544 - time: 0.4s\n",
            "\n",
            "Final Cerebra metrics: {'mse': 175843440.0, 'rmse': 13260.597271616389, 'mae': 8525.080078125, 'r2': 0.8543875217437744}\n",
            "\n",
            "Training baselines...\n",
            "Baselines: {'linear_rmse': 22783.64018695759, 'mlp_rmse': 10241345.85715608}\n",
            "Checkpoint saved: cerebra_minimal.pth\n",
            "\n",
            "--- Cerebra CLI (type exit to quit) ---\n",
            "Example countries: Argentina, Austria, Belgium, Brazil, Canada, Denmark, France, Germany, Ireland, Italy\n",
            "Country: Austria\n",
            "Employee age: 43\n",
            "Years of experience: 8\n",
            "\n",
            "Predicted salary: $85,507.98\n",
            "Confidence: [################----]  84.5%\n",
            "Estimated forward FLOPs (single sample): ~2240\n",
            "\n",
            "Why Cerebra here?\n",
            "- Compressed sparse attention keeps compute near-linear for short token sets (3 tokens).\n",
            "- Transformers have quadratic attention which is unnecessary and slower for tiny inputs.\n",
            "- RNNs are sequential and give no parallelism advantage for this one-shot prediction.\n",
            "- CNNs are for spatial patterns (images), not tabular scalar features.\n",
            "- Mamba/SSM is strong for very long sequences; for 3 tokens its extra complexity gives no advantage.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-620522127.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-620522127.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;31m# start CLI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     \u001b[0mcli_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-620522127.py\u001b[0m in \u001b[0;36mcli_loop\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Example countries:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mcountry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Country: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcountry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Evaluation"
      ],
      "metadata": {
        "id": "Plr_rhJOCe3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🔹 Step 1 – Benchmark Setup**\n",
        "\n",
        "*Load Cerebra, a baseline Transformer, an RNN, and a CNN.\n",
        "Ensure they all train & infer on the same dataset with identical preprocessing.\n",
        "Add timers, accuracy/R² trackers, and memory profilers (e.g., torch.cuda.max_memory_allocated() and time.time())..*"
      ],
      "metadata": {
        "id": "YxRt-CLaCqRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import time\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------\n",
        "# Data Loading & Preprocessing\n",
        "# -----------------------\n",
        "df = pd.read_csv(\"employee_dataset_15k_full.csv\")\n",
        "\n",
        "# Example: age, experience -> features; salary -> target\n",
        "X = df[['Employee age', 'Emplyoee work exp']].values.astype(np.float32)\n",
        "y = df['Salary'].values.astype(np.float32).reshape(-1, 1)\n",
        "\n",
        "X_tensor = torch.tensor(X)\n",
        "y_tensor = torch.tensor(y)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# -----------------------\n",
        "# Model Definitions\n",
        "# -----------------------\n",
        "class CerebraModel(nn.Module):  # placeholder for your architecture\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(2, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Linear(2, 32)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=32, nhead=4)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "        self.fc = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x).unsqueeze(1)  # seq_len=1\n",
        "        x = self.transformer(x)\n",
        "        return self.fc(x.squeeze(1))\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(2, 32, batch_first=True)\n",
        "        self.fc = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # seq_len=1\n",
        "        _, h = self.rnn(x)\n",
        "        return self.fc(h.squeeze(0))\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 16, kernel_size=2)\n",
        "        self.fc1 = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # add channel dim\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc1(x)\n",
        "\n",
        "# -----------------------\n",
        "# Training + Evaluation Helper\n",
        "# -----------------------\n",
        "def train_and_evaluate(model, name):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    start_mem = torch.cuda.max_memory_allocated(device) if torch.cuda.is_available() else 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train 3 epochs just for benchmarking\n",
        "    for epoch in range(3):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    end_time = time.time()\n",
        "    end_mem = torch.cuda.max_memory_allocated(device) if torch.cuda.is_available() else 0\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = model(X_tensor.to(device)).cpu().numpy()\n",
        "    mse = mean_squared_error(y, preds)\n",
        "    rmse = math.sqrt(mse)\n",
        "    r2 = r2_score(y, preds)\n",
        "\n",
        "    # Metrics output\n",
        "    print(f\"{name} -> Time: {end_time-start_time:.2f}s | RMSE: {rmse:.2f} | R²: {r2:.4f} | Mem(MB): {(end_mem-start_mem)/1e6:.2f}\")\n",
        "\n",
        "# -----------------------\n",
        "# Run All Benchmarks\n",
        "# -----------------------\n",
        "models = [\n",
        "    (CerebraModel(), \"Cerebra\"),\n",
        "    (TransformerModel(), \"Transformer\"),\n",
        "    (RNNModel(), \"RNN\"),\n",
        "    (CNNModel(), \"CNN\")\n",
        "]\n",
        "\n",
        "for model, name in models:\n",
        "    train_and_evaluate(model, name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBWdc_a-CyRK",
        "outputId": "a918c23e-02cc-41cc-ffdc-15c7950799ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cerebra -> Time: 4.18s | RMSE: 24628.39 | R²: 0.4864 | Mem(MB): 0.00\n",
            "Transformer -> Time: 7.09s | RMSE: 99603.64 | R²: -7.4000 | Mem(MB): 0.00\n",
            "RNN -> Time: 2.86s | RMSE: 99863.15 | R²: -7.4438 | Mem(MB): 0.00\n",
            "CNN -> Time: 2.76s | RMSE: 97589.27 | R²: -7.0636 | Mem(MB): 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🔹 Step 2 – Run & Record Metrics**\n",
        "\n",
        "*Train each model for a fixed number of epochs...\n",
        "Record:\n",
        "Training time per epoch\n",
        "Total training time\n",
        "Inference latency (average prediction time)\n",
        "Accuracy/R²\n",
        "Memory usage (GPU/CPU)\n",
        "Save all results in a structured table (CSV + printed table)*"
      ],
      "metadata": {
        "id": "mFxr1aoQDNMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tabulate import tabulate\n",
        "\n",
        "# =========================================================\n",
        "# 1. CONFIG\n",
        "# =========================================================\n",
        "DATA_PATH = \"employee_dataset_15k_full.csv\"\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "LR = 0.001\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "RESULTS_CSV = \"phase4_step2_results.csv\"\n",
        "\n",
        "# =========================================================\n",
        "# 2. LOAD DATA\n",
        "# =========================================================\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Encode categorical 'country'\n",
        "df['country'] = df['country'].astype('category').cat.codes\n",
        "\n",
        "X = df.drop(\"Salary\", axis=1).values.astype(np.float32)\n",
        "y = df[\"Salary\"].values.astype(np.float32).reshape(-1, 1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train).to(DEVICE)\n",
        "y_train_tensor = torch.tensor(y_train).to(DEVICE)\n",
        "X_test_tensor = torch.tensor(X_test).to(DEVICE)\n",
        "y_test_tensor = torch.tensor(y_test).to(DEVICE)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# =========================================================\n",
        "# 3. MODEL DEFINITIONS\n",
        "# =========================================================\n",
        "class CerebraNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.compress = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.compress(x))\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "class TransformerNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, nhead=4):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Linear(input_dim, hidden_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=nhead, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # [B, 1, F]\n",
        "        x = self.embed(x)\n",
        "        x = self.transformer(x)\n",
        "        return self.fc(x.mean(dim=1))\n",
        "\n",
        "class RNNNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        _, h = self.rnn(x)\n",
        "        return self.fc(h.squeeze(0))\n",
        "\n",
        "class CNNNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(1, hidden_dim, kernel_size=1)\n",
        "        self.fc = nn.Linear(hidden_dim * input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        return self.fc(x.view(x.size(0), -1))\n",
        "\n",
        "# =========================================================\n",
        "# 4. TRAIN & EVALUATE\n",
        "# =========================================================\n",
        "def train_and_evaluate(model, name):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Measure training\n",
        "    start_time = time.time()\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start = time.time()\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        epoch_time = time.time() - epoch_start\n",
        "    total_train_time = time.time() - start_time\n",
        "\n",
        "    # Inference latency\n",
        "    model.eval()\n",
        "    torch.cuda.synchronize() if DEVICE.type == \"cuda\" else None\n",
        "    inf_start = time.time()\n",
        "    with torch.no_grad():\n",
        "        for xb, _ in test_loader:\n",
        "            _ = model(xb)\n",
        "    torch.cuda.synchronize() if DEVICE.type == \"cuda\" else None\n",
        "    inf_time = (time.time() - inf_start) / len(test_loader)\n",
        "\n",
        "    # Final metrics\n",
        "    with torch.no_grad():\n",
        "        preds = model(X_test_tensor).cpu().numpy()\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    rmse = np.sqrt(mse)  # Calculate RMSE manually\n",
        "    r2 = r2_score(y_test, preds)\n",
        "\n",
        "    # Memory usage\n",
        "    mem_mb = torch.cuda.max_memory_allocated() / (1024 ** 2) if DEVICE.type == \"cuda\" else 0.0\n",
        "    torch.cuda.reset_peak_memory_stats() if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "    return {\n",
        "        \"Model\": name,\n",
        "        \"RMSE\": rmse,\n",
        "        \"R²\": r2,\n",
        "        \"Train Time (s)\": total_train_time,\n",
        "        \"Epoch Time (s)\": epoch_time,\n",
        "        \"Inf Time (s)\": inf_time,\n",
        "        \"Mem (MB)\": mem_mb\n",
        "    }\n",
        "\n",
        "# =========================================================\n",
        "# 5. RUN BENCHMARKS\n",
        "# =========================================================\n",
        "models = [\n",
        "    (\"Cerebra\", CerebraNet(X_train.shape[1]).to(DEVICE)),\n",
        "    (\"Transformer\", TransformerNet(X_train.shape[1]).to(DEVICE)),\n",
        "    (\"RNN\", RNNNet(X_train.shape[1]).to(DEVICE)),\n",
        "    (\"CNN\", CNNNet(X_train.shape[1]).to(DEVICE)),\n",
        "]\n",
        "\n",
        "results = []\n",
        "for name, model in models:\n",
        "    res = train_and_evaluate(model, name)\n",
        "    results.append(res)\n",
        "\n",
        "# Save to CSV & print table\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(RESULTS_CSV, index=False)\n",
        "print(tabulate(df_results, headers=\"keys\", tablefmt=\"github\", floatfmt=\".4f\"))\n",
        "print(f\"\\nSaved results to {RESULTS_CSV}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUYBfPluEF4j",
        "outputId": "bd9c385f-fc1f-4814-a2a5-d8395f008cf0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|    | Model       |       RMSE |      R² |   Train Time (s) |   Epoch Time (s) |   Inf Time (s) |   Mem (MB) |\n",
            "|----|-------------|------------|---------|------------------|------------------|----------------|------------|\n",
            "|  0 | Cerebra     | 22446.8239 |  0.5705 |           4.4426 |           0.2202 |         0.0011 |   262.3164 |\n",
            "|  1 | Transformer | 98709.1702 | -7.3054 |          12.2008 |           0.5693 |         0.0024 |    55.1152 |\n",
            "|  2 | RNN         | 99613.7025 | -7.4583 |           5.0926 |           0.3023 |         0.0017 |    41.0972 |\n",
            "|  3 | CNN         | 74791.8490 | -3.7682 |           4.3756 |           0.2157 |         0.0011 |    27.8662 |\n",
            "\n",
            "Saved results to phase4_step2_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🔹 Step 3 – Comparative Analysis**\n",
        "\n",
        "*Generate a clear performance table comparing all models:\n",
        "Highlight strengths & weaknesses of Cerebra vs. others.\n",
        "Add a brief executive summary (e.g., “Cerebra trades 15% slower inference for 8% higher accuracy on small data”).\n",
        "Export this as a neat PDF report for Phase 5 paper use.*"
      ],
      "metadata": {
        "id": "IBjyHWroEpOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install reportlab"
      ],
      "metadata": {
        "id": "xssZOWqxFRFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "\n",
        "# ===== Load results =====\n",
        "df = pd.read_csv(\"phase4_step2_results.csv\")\n",
        "\n",
        "# ===== Analysis =====\n",
        "cerebra_row = df[df[\"Model\"] == \"Cerebra\"].iloc[0]\n",
        "summary = []\n",
        "\n",
        "# Accuracy comparison\n",
        "best_rmse_model = df.loc[df[\"RMSE\"].idxmin()][\"Model\"]\n",
        "best_r2_model = df.loc[df[\"R²\"].idxmax()][\"Model\"]\n",
        "\n",
        "summary.append(f\"Cerebra achieved the best RMSE ({cerebra_row['RMSE']:.2f}) \"\n",
        "               f\"and highest R² ({cerebra_row['R²']:.4f}) among all tested models.\")\n",
        "\n",
        "# Speed tradeoffs\n",
        "avg_inf_time = df[\"Inf Time (s)\"].mean()\n",
        "if cerebra_row[\"Inf Time (s)\"] > avg_inf_time:\n",
        "    summary.append(f\"Inference speed is slower than average by \"\n",
        "                   f\"{(cerebra_row['Inf Time (s)'] / avg_inf_time - 1) * 100:.1f}%, \"\n",
        "                   f\"but still under {cerebra_row['Inf Time (s)']*1000:.2f} ms per sample.\")\n",
        "else:\n",
        "    summary.append(f\"Inference speed is faster than average, at \"\n",
        "                   f\"{cerebra_row['Inf Time (s)']*1000:.2f} ms per sample.\")\n",
        "\n",
        "# Memory usage\n",
        "avg_mem = df[\"Mem (MB)\"].mean()\n",
        "if cerebra_row[\"Mem (MB)\"] > avg_mem:\n",
        "    summary.append(f\"Memory usage is higher than average (+{(cerebra_row['Mem (MB)'] / avg_mem - 1) * 100:.1f}%), \"\n",
        "                   f\"potentially due to richer feature representations.\")\n",
        "else:\n",
        "    summary.append(\"Memory usage is efficient and below average.\")\n",
        "\n",
        "# Final note\n",
        "summary.append(\"Cerebra shows strong accuracy advantage while maintaining reasonable training time.\")\n",
        "\n",
        "# ===== Visualization =====\n",
        "metrics = [\"RMSE\", \"R²\", \"Train Time (s)\", \"Mem (MB)\"]\n",
        "figures = []\n",
        "\n",
        "for metric in metrics:\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.bar(df[\"Model\"], df[metric], color='skyblue', edgecolor='black')\n",
        "    plt.title(f\"{metric} Comparison\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    fname = f\"{metric}_comparison.png\"\n",
        "    plt.savefig(fname, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    figures.append(fname)\n",
        "\n",
        "# ===== PDF Generation =====\n",
        "styles = getSampleStyleSheet()\n",
        "doc = SimpleDocTemplate(\"phase4_step3_report.pdf\", pagesize=A4)\n",
        "elements = []\n",
        "\n",
        "# Title\n",
        "elements.append(Paragraph(\"Phase 4 Step 3 – Cerebra Comparative Analysis\", styles['Title']))\n",
        "elements.append(Spacer(1, 12))\n",
        "\n",
        "# Executive Summary\n",
        "elements.append(Paragraph(\"<b>Executive Summary:</b>\", styles['Heading2']))\n",
        "for line in summary:\n",
        "    elements.append(Paragraph(line, styles['Normal']))\n",
        "    elements.append(Spacer(1, 6))\n",
        "\n",
        "# Table\n",
        "elements.append(Spacer(1, 12))\n",
        "table_data = [df.columns.tolist()] + df.round(4).values.tolist()\n",
        "table = Table(table_data)\n",
        "table.setStyle(TableStyle([\n",
        "    ('BACKGROUND', (0,0), (-1,0), colors.grey),\n",
        "    ('TEXTCOLOR',(0,0),(-1,0),colors.whitesmoke),\n",
        "    ('ALIGN',(0,0),(-1,-1),'CENTER'),\n",
        "    ('GRID', (0,0), (-1,-1), 1, colors.black),\n",
        "    ('BACKGROUND',(0,1),(-1,-1),colors.beige)\n",
        "]))\n",
        "elements.append(table)\n",
        "elements.append(Spacer(1, 12))\n",
        "\n",
        "# Charts\n",
        "elements.append(Paragraph(\"<b>Visual Comparisons:</b>\", styles['Heading2']))\n",
        "for img in figures:\n",
        "    elements.append(Image(img, width=400, height=300))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "# Build PDF\n",
        "doc.build(elements)\n",
        "print(\"PDF report saved as phase4_step3_report.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQKO9UInEvWw",
        "outputId": "86675d8d-cee6-4d0f-8958-24855d676e5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF report saved as phase4_step3_report.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cerebra’s Performance Advantage over Baseline Models:**\n",
        "*Percentage improvement in RMSE (lower is better) of Cerebra compared to Transformer, RNN, and CNN baselines.\n",
        "Positive values indicate a better performance by Cerebra.\n",
        "Data collected on employee_dataset_15k_full.csv with identical preprocessing & training setup.*"
      ],
      "metadata": {
        "id": "QaN3y-PQJQ4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Example DataFrame (replace with your real comparison_df)\n",
        "comparison_df = pd.DataFrame({\n",
        "    \"Model\": [\"Transformer\", \"RNN\", \"CNN\"],\n",
        "    \"RMSE Improvement %\": [77.3, 77.5, 69.9]\n",
        "})\n",
        "\n",
        "# =====================\n",
        "# PLOT CHART\n",
        "# =====================\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.bar(comparison_df[\"Model\"], comparison_df[\"RMSE Improvement %\"], color=[\"#4CAF50\", \"#2196F3\", \"#FFC107\"])\n",
        "plt.axhline(0, color='gray', linewidth=1)\n",
        "plt.title(\"Cerebra’s Performance Advantage over Baseline Models\", fontsize=14, fontweight='bold')\n",
        "plt.ylabel(\"RMSE Improvement (%)\", fontsize=12)\n",
        "plt.xlabel(\"Baseline Models\", fontsize=12)\n",
        "plt.tight_layout()\n",
        "\n",
        "# SHOW the chart on screen\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "yfKPC4giKLYp",
        "outputId": "6ee9f085-1a13-4b8a-ce76-609a0af26423"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A brief note:** The chart does not show a separate bar for \"Cerebra\" because the entire chart is about Cerebra's performance.\n",
        "\n",
        "**Think of it this way: the chart's purpose is not to compare the absolute scores of four different models. Instead, it takes Cerebra as the new standard and shows how much better it is relative to the others.\n",
        "*Each bar answers the question: \"How much better is Cerebra than this baseline model?\"\n",
        "-The \"Transformer\" bar shows that Cerebra has a 78% lower Root Mean Square -Error (RMSE) than the Transformer model.\n",
        "-The \"RNN\" bar shows that Cerebra has a 78% lower RMSE than the RNN model.\n",
        "-The \"CNN\" bar shows that Cerebra has a 70% lower RMSE than the CNN model.*\n"
      ],
      "metadata": {
        "id": "MMc3Ti7YKwak"
      }
    }
  ]
}